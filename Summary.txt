Sequence Alignment Problem


Sequence Alignment Problem deals with the fundamental problem of quantifying the similarities between strings.
We model the similarity of two strings by determing the number of gaps and mismatches we incur when we line up the strings.
The objective is to find the minimum "cost" alignment of two strings to quantify their similarity (or dissimilarity).

Finding efficient solution to this problem becomes increasing important as we deal with extremely large strings,
such as DNA and/or chromosome strings. Even though they have small alphabets (A,C,G,T), the strings can go upto
3 billion in length. Such comparison is important to understand an organism's genome to determine its properties.

Hence, solution to these problems have wide-ranging uses from use in spell checkers to computational biology.


Two Algorithms (Description, Time Complexity, Implementation)


The first algorithm that has been used, termed as the basic algorithm, is a dynamic programming based.
It finds the minimum cost alignment of the two strings.

We define its recurrence relation as
OPT(i,j) = min[mismatch(xi, yj) + OPT(i - 1, j - 1), gapPenalty + OPT(i - 1, j), gapPenalty + OPT(i, j - 1)]

where xi, yj are characters in the two strings (let's say) X and Y,
and OPT is the minimum cost of an alignment between x1x2...xi and y1y2...yj

This yields us an overall time complexity of O(mn), as the finding mismatch and deciding between mismatch and gapPenalty
is O(1) and we have to make O(mn) iterations.

We store the result in a 2D array of size O(mn) as to get back the optimal alignment at the end of finding the cost.

We can reduce the space complexity by using 1D array and have size O(m + n) but we would not be able get the optimal
alignment.

The second algorithm that has been used, termed as the efficient algorithm, is hybrid algorithm that uses
divide and conquer and dynamic programming.

It uses the dynamic programming space efficient solution to get the cost as well as the alignment.

The crux of the algorithm is to find in each iteration a partition point such that the shortest alignment
(corner to corner path) must include it. As we keep on dividing the problem, we are able to reuse the memory from one
call to the next.

This yields a space complexity of O(m + n).

The algorithm involves multiples iteration of the space efficient dynamic programming solution, however is bounded to
at most 2cmn call where c is a constant. Hence, the time complexity is O(mn).

If we consider two 3 billion length strings, the space required by the basic algorithm would be 3B * 3B integers.
The space required by the efficient algorithm would be 3B integers.

That is a huge savings in space with at most 2x runtime cost.


Observation of certain data sets


On average, the efficient version has runtime is 1.1x slower than the basic version, but uses 22x less space than
the basic version (excluding certain datasets which use not all alphabets).

The trend of the 2x runtime and large space savings can be seen in increasing string lengths with ACGT characters.
However, if the characters are restricted to just two in each string or 2 across both the strings with large string
size, the efficient algorithms seems to perform close to or better than the basic algorithm.

This was seen with high code optimization set on the compiler and not otherwise.
Further analysis is needed to understand why.